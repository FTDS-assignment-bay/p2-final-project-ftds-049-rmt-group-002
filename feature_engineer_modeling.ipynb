{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb91c40",
   "metadata": {},
   "source": [
    "# i. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47acb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "from coffee_rec import UserPref, build_profile\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea91a33d",
   "metadata": {},
   "source": [
    "# ii. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c554c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"EDA/tokopedia_products_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67372331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8)\n",
      "Index(['source', 'name', 'price', 'description', 'origin', 'process',\n",
      "       'roast_level', 'notes'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>origin</th>\n",
       "      <th>process</th>\n",
       "      <th>roast_level</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>instinct roastery</td>\n",
       "      <td>candy apple espresso roast  instinct roastery ...</td>\n",
       "      <td>195000</td>\n",
       "      <td>50 toraja washed  20 colombia sequoias waterme...</td>\n",
       "      <td>colombia, toraja, flores</td>\n",
       "      <td>washed, natural</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fruity, sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instinct roastery</td>\n",
       "      <td>ethiopia tima washed  instinct roastery  150 gram</td>\n",
       "      <td>185000</td>\n",
       "      <td>region  guji process  washed variety  74110 al...</td>\n",
       "      <td>ethiopia</td>\n",
       "      <td>washed</td>\n",
       "      <td>light</td>\n",
       "      <td>floral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instinct roastery</td>\n",
       "      <td>espresso roast kenya tatu  instinct roastery  ...</td>\n",
       "      <td>195000</td>\n",
       "      <td>process  natural region  kiambu county farm  t...</td>\n",
       "      <td>kenya</td>\n",
       "      <td>washed, natural</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>instinct roastery</td>\n",
       "      <td>ethiopia sidama baturo  instinct roastery  150...</td>\n",
       "      <td>220000</td>\n",
       "      <td>process  anaerobic natural variety  74158 regi...</td>\n",
       "      <td>ethiopia</td>\n",
       "      <td>natural, anaerobic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>fruity, herbal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instinct roastery</td>\n",
       "      <td>colombia eliecer ordez  instinct roastery  150...</td>\n",
       "      <td>175000</td>\n",
       "      <td>process  washed variety  pink bourbon region  ...</td>\n",
       "      <td>colombia</td>\n",
       "      <td>washed</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                                               name  \\\n",
       "0  instinct roastery  candy apple espresso roast  instinct roastery ...   \n",
       "1  instinct roastery  ethiopia tima washed  instinct roastery  150 gram   \n",
       "2  instinct roastery  espresso roast kenya tatu  instinct roastery  ...   \n",
       "3  instinct roastery  ethiopia sidama baturo  instinct roastery  150...   \n",
       "4  instinct roastery  colombia eliecer ordez  instinct roastery  150...   \n",
       "\n",
       "    price                                        description  \\\n",
       "0  195000  50 toraja washed  20 colombia sequoias waterme...   \n",
       "1  185000  region  guji process  washed variety  74110 al...   \n",
       "2  195000  process  natural region  kiambu county farm  t...   \n",
       "3  220000  process  anaerobic natural variety  74158 regi...   \n",
       "4  175000  process  washed variety  pink bourbon region  ...   \n",
       "\n",
       "                     origin             process roast_level           notes  \n",
       "0  colombia, toraja, flores     washed, natural     unknown   fruity, sweet  \n",
       "1                  ethiopia              washed       light          floral  \n",
       "2                     kenya     washed, natural     unknown           sweet  \n",
       "3                  ethiopia  natural, anaerobic     unknown  fruity, herbal  \n",
       "4                  colombia              washed     unknown           sweet  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8f1f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   source       614 non-null    object\n",
      " 1   name         614 non-null    object\n",
      " 2   price        614 non-null    int64 \n",
      " 3   description  614 non-null    object\n",
      " 4   origin       614 non-null    object\n",
      " 5   process      614 non-null    object\n",
      " 6   roast_level  614 non-null    object\n",
      " 7   notes        614 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 38.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data type\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad8460",
   "metadata": {},
   "source": [
    "# iii. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b433076",
   "metadata": {},
   "source": [
    "## 3.1 Expected Feature-Engineered Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c78d80",
   "metadata": {},
   "source": [
    "In this step, we freeze an output contract: the exact set of columns our Feature Engineering must produce so the downstream pipeline (TF-IDF, cosine similarity, reranking) remains stable. This matters because datasets evolve; without a clear schema contract, a small change (missing/renamed columns) can break the notebook or silently degrade recommendation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5837b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we need from the RAW dataset (minimum to run FE safely)\n",
    "REQUIRED_RAW_COLS = [\"source\", \"name\", \"price\", \"description\"]\n",
    "\n",
    "# Columns we promise to produce after FEATURE ENGINEERING (downstream contract)\n",
    "REQUIRED_FE_COLS = [\n",
    "    # identity\n",
    "    \"source\", \"name\", \"price\", \"description\",\n",
    "    # normalized text\n",
    "    \"name_clean\", \"desc_clean\", \"raw_text\",\n",
    "    # ranking flags\n",
    "    \"is_house_blend\", \"is_blend\", \"is_capsule\", \"is_liquid\", \"is_merch_tools\",\n",
    "    # structured coffee profile\n",
    "    \"process\", \"roast\", \"bean_type\", \"notes\", \"notes_str\",\n",
    "    # TF-IDF main input\n",
    "    \"match_text\",\n",
    "    # optional but recommended to keep if available\n",
    "    \"origin\",\n",
    "]\n",
    "\n",
    "# Create a function to validate columns\n",
    "def assert_columns_exist(df, required_cols, stage_name=\"\"):\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"[{stage_name}] Missing required columns: {missing}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fbc9b",
   "metadata": {},
   "source": [
    "## 3.2 Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09c7948",
   "metadata": {},
   "source": [
    "In this step, we create clean, consistent text versions of name and description through simple normalization: lowercasing, whitespace cleanup, and safe missing-value handling. The outputs are name_clean, desc_clean, and a combined raw_text. This matters because marketplace text is noisy (random casing, messy spacing, inconsistent formatting). Normalized text makes keyword-based flags (capsule/liquid/tools) more reliable, and it gives us a strong fallback source in case new structured columns (process/notes) are missing or inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f69ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          name_clean  \\\n",
      "0  candy apple espresso roast instinct roastery 2...   \n",
      "1    ethiopia tima washed instinct roastery 150 gram   \n",
      "2  espresso roast kenya tatu instinct roastery 20...   \n",
      "3  ethiopia sidama baturo instinct roastery 150 gram   \n",
      "4  colombia eliecer ordez instinct roastery 150 gram   \n",
      "\n",
      "                                          desc_clean  \\\n",
      "0  50 toraja washed 20 colombia sequoias watermel...   \n",
      "1  region guji process washed variety 74110 altit...   \n",
      "2  process natural region kiambu county farm tatu...   \n",
      "3  process anaerobic natural variety 74158 region...   \n",
      "4  process washed variety pink bourbon region hui...   \n",
      "\n",
      "                                            raw_text  \n",
      "0  candy apple espresso roast instinct roastery 2...  \n",
      "1  ethiopia tima washed instinct roastery 150 gra...  \n",
      "2  espresso roast kenya tatu instinct roastery 20...  \n",
      "3  ethiopia sidama baturo instinct roastery 150 g...  \n",
      "4  colombia eliecer ordez instinct roastery 150 g...  \n"
     ]
    }
   ],
   "source": [
    "def normalize_text(s: Any) -> str:\n",
    "    \"\"\"\n",
    "    Normalize text safely for downstream keyword/regex logic.\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Normalize key text fields\n",
    "df[\"name_clean\"] = df[\"name\"].apply(normalize_text)\n",
    "df[\"desc_clean\"] = df[\"description\"].apply(normalize_text)\n",
    "\n",
    "# Build raw_text (foundation for flags + fallback extraction)\n",
    "df[\"raw_text\"] = (df[\"name_clean\"] + \" \" + df[\"desc_clean\"]).str.strip()\n",
    "\n",
    "# Quick check\n",
    "print(df[[\"name_clean\", \"desc_clean\", \"raw_text\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e9972",
   "metadata": {},
   "source": [
    "## 3.3 Create Important Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d81d3",
   "metadata": {},
   "source": [
    "In this step, we create boolean flags (True/False) to label product types such as capsules, ready-to-drink/liquid, brewing tools/merch, blend, and house blend. This matters because our recommender is meant to serve “coffee beans,” but marketplace listings often include look-alike items with similar wording (e.g., “filter” appears in tools, not beans). These flags become business guardrails for the ranking/penalty layer: if users want beans, we should avoid pushing V60, drip bags, capsules, or RTD drinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81070039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            raw_text  is_house_blend  \\\n",
      "0  candy apple espresso roast instinct roastery 2...           False   \n",
      "1  ethiopia tima washed instinct roastery 150 gra...           False   \n",
      "2  espresso roast kenya tatu instinct roastery 20...           False   \n",
      "3  ethiopia sidama baturo instinct roastery 150 g...           False   \n",
      "4  colombia eliecer ordez instinct roastery 150 g...           False   \n",
      "\n",
      "   is_blend  is_capsule  is_liquid  is_merch_tools  \n",
      "0      True       False       True           False  \n",
      "1     False       False      False           False  \n",
      "2     False       False      False           False  \n",
      "3     False       False      False           False  \n",
      "4     False       False       True           False  \n",
      "\n",
      "Flag counts:\n",
      "is_house_blend     10\n",
      "is_blend           90\n",
      "is_capsule          8\n",
      "is_liquid         217\n",
      "is_merch_tools    402\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def contains_any(text: str, keywords: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if any keyword appears in the given text.\n",
    "    \"\"\"\n",
    "\n",
    "    if not text:\n",
    "        return False\n",
    "    return any(k in text for k in keywords)\n",
    "\n",
    "# Keyword sets\n",
    "kw_house_blend = [\"house blend\", \"signature blend\"]\n",
    "kw_blend = [\" blend\", \"espresso blend\", \"arabica robusta blend\"]  # note the leading space to reduce false hits\n",
    "kw_capsule = [\"capsule\", \"capsules\", \"nespresso\", \"dolce gusto\", \"k-cup\", \"kcup\", \"pod\", \"coffee pod\"]\n",
    "kw_liquid = [\n",
    "    \"ml\", \"m l\", \"liter\", \"litre\", \"milliliter\", \"ready to drink\", \"rtd\",\n",
    "    \"bottle\", \"botol\", \"can\", \"kaleng\", \"cold brew\", \"latte\", \"milk coffee\"\n",
    "]\n",
    "kw_merch_tools = [\n",
    "    \"v60\", \"drip bag\", \"dripbag\", \"filter paper\", \"paper filter\", \"aeropress\",\n",
    "    \"french press\", \"moka pot\", \"grinder\", \"hand grinder\", \"tamper\", \"server\",\n",
    "    \"kettle\", \"gooseneck\", \"scale\", \"milk jug\", \"pitcher\"\n",
    "]\n",
    "\n",
    "# Build flags\n",
    "df[\"is_house_blend\"] = df[\"raw_text\"].apply(lambda t: contains_any(t, kw_house_blend))\n",
    "df[\"is_blend\"] = df[\"raw_text\"].apply(lambda t: contains_any(t, kw_blend))\n",
    "df[\"is_capsule\"] = df[\"raw_text\"].apply(lambda t: contains_any(t, kw_capsule))\n",
    "df[\"is_liquid\"] = df[\"raw_text\"].apply(lambda t: contains_any(t, kw_liquid))\n",
    "df[\"is_merch_tools\"] = df[\"raw_text\"].apply(lambda t: contains_any(t, kw_merch_tools))\n",
    "\n",
    "# Quick check\n",
    "print(df[[\"raw_text\", \"is_house_blend\", \"is_blend\", \"is_capsule\", \"is_liquid\", \"is_merch_tools\"]].head(5))\n",
    "print(\"\\nFlag counts:\")\n",
    "print(df[[\"is_house_blend\", \"is_blend\", \"is_capsule\", \"is_liquid\", \"is_merch_tools\"]].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd24a33",
   "metadata": {},
   "source": [
    "## 3.4 Create Coffee Profile Attribute Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8f387",
   "metadata": {},
   "source": [
    "In this step, we rebuild the coffee profile attributes (process, roast, notes, origin) using a hybrid approach. We trust explicit columns from the updated dataset as the primary source of truth (they’re usually cleaner and more consistent), then fallback to raw_text extraction only when those explicit values are missing or invalid. This matters because it improves recommendation quality (better signals) while keeping the system robust when marketplace data is messy or incomplete. The outputs here feed directly into match_text (TF-IDF) and the ranking/penalty layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff60366f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null/empty checks (count of empty strings):\n",
      "{'process_empty': 168, 'roast_empty': 95, 'notes_empty': 0, 'origin_empty': 0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>process</th>\n",
       "      <th>roast</th>\n",
       "      <th>notes_str</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candy apple espresso roast instinct roastery 2...</td>\n",
       "      <td>washed</td>\n",
       "      <td>espresso</td>\n",
       "      <td>fruity sweet</td>\n",
       "      <td>colombia, toraja, flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ethiopia tima washed instinct roastery 150 gra...</td>\n",
       "      <td>washed</td>\n",
       "      <td>light</td>\n",
       "      <td>floral</td>\n",
       "      <td>ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>espresso roast kenya tatu instinct roastery 20...</td>\n",
       "      <td>washed</td>\n",
       "      <td>espresso</td>\n",
       "      <td>sweet</td>\n",
       "      <td>kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethiopia sidama baturo instinct roastery 150 g...</td>\n",
       "      <td>natural</td>\n",
       "      <td></td>\n",
       "      <td>fruity herbal</td>\n",
       "      <td>ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colombia eliecer ordez instinct roastery 150 g...</td>\n",
       "      <td>washed</td>\n",
       "      <td></td>\n",
       "      <td>sweet</td>\n",
       "      <td>colombia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  process     roast  \\\n",
       "0  candy apple espresso roast instinct roastery 2...   washed  espresso   \n",
       "1  ethiopia tima washed instinct roastery 150 gra...   washed     light   \n",
       "2  espresso roast kenya tatu instinct roastery 20...   washed  espresso   \n",
       "3  ethiopia sidama baturo instinct roastery 150 g...  natural             \n",
       "4  colombia eliecer ordez instinct roastery 150 g...   washed             \n",
       "\n",
       "       notes_str                    origin  \n",
       "0   fruity sweet  colombia, toraja, flores  \n",
       "1         floral                  ethiopia  \n",
       "2          sweet                     kenya  \n",
       "3  fruity herbal                  ethiopia  \n",
       "4          sweet                  colombia  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helpers for normalization/mapping\n",
    "def norm_str(x) -> str:\n",
    "    \"\"\"\n",
    "    Safely normalize any value into a clean lowercase string.\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", str(x).strip().lower())\n",
    "\n",
    "def normalize_process(val: str) -> str:\n",
    "    \"\"\"\n",
    "    Map process text into our canonical labels: washed/natural/honey/anaerobic (or empty).\n",
    "    \"\"\"\n",
    "    \n",
    "    s = norm_str(val)\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    if \"wash\" in s:\n",
    "        return \"washed\"\n",
    "    if \"natural\" in s:\n",
    "        return \"natural\"\n",
    "    if \"honey\" in s:\n",
    "        return \"honey\"\n",
    "    if \"anaer\" in s:\n",
    "        return \"anaerobic\"\n",
    "    return \"\"\n",
    "\n",
    "def map_roast_level(val: str) -> str:\n",
    "    \"\"\"\n",
    "    Map dataset roast_level into: light/medium/dark/espresso (or empty).\n",
    "    Adjust mapping here if your dataset uses different labels.\n",
    "    \"\"\"\n",
    "\n",
    "    s = norm_str(val)\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    # Common variants\n",
    "    if \"espresso\" in s:\n",
    "        return \"espresso\"\n",
    "    if \"dark\" in s:\n",
    "        return \"dark\"\n",
    "    if \"medium\" in s:\n",
    "        return \"medium\"\n",
    "    if \"light\" in s:\n",
    "        return \"light\"\n",
    "\n",
    "    # Sometimes datasets use \"city/full city/french/italian\" etc.\n",
    "    if \"french\" in s or \"italian\" in s:\n",
    "        return \"dark\"\n",
    "    if \"full city\" in s or \"city+\" in s:\n",
    "        return \"medium\"\n",
    "    if \"city\" in s:\n",
    "        return \"light\"\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def normalize_notes(val: str) -> str:\n",
    "    \"\"\"\n",
    "    Make notes consistent.\n",
    "    Output: a single string, e.g. \"fruity floral chocolate_nutty\"\n",
    "    \"\"\"\n",
    "    s = norm_str(val)\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    # Split by commas/slashes/pipes\n",
    "    parts = re.split(r\"[,\\|/;]+\", s)\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "    # Lightweight synonym mapping\n",
    "    mapped = []\n",
    "    for p in parts:\n",
    "        if \"chocolate\" in p or \"cocoa\" in p or \"nut\" in p:\n",
    "            mapped.append(\"chocolate_nutty\")\n",
    "        elif \"floral\" in p or \"jasmine\" in p or \"rose\" in p:\n",
    "            mapped.append(\"floral\")\n",
    "        elif \"citrus\" in p or \"berry\" in p or \"apple\" in p or \"grape\" in p or \"tropical\" in p or \"fruity\" in p:\n",
    "            mapped.append(\"fruity\")\n",
    "        elif \"spice\" in p or \"cinnamon\" in p or \"clove\" in p:\n",
    "            mapped.append(\"spicy\")\n",
    "        elif \"sweet\" in p or \"honey\" in p or \"vanilla\" in p or \"brown sugar\" in p:\n",
    "            mapped.append(\"sweet\")\n",
    "        else:\n",
    "            # Keep raw token\n",
    "            mapped.append(p.replace(\" \", \"_\"))\n",
    "\n",
    "    # Dedup while preserving order\n",
    "    mapped = list(dict.fromkeys(mapped))\n",
    "    return \" \".join(mapped)\n",
    "\n",
    "def normalize_origin(val: str) -> str:\n",
    "    \"\"\"Keep origin as-is but normalized lightly (string, lowercase, trimmed).\"\"\"\n",
    "    return norm_str(val)\n",
    "\n",
    "\n",
    "# Fallback extractors from raw_text (only used when explicit is missing/invalid)\n",
    "\n",
    "def extract_one(text: str, patterns: dict) -> str:\n",
    "    \"\"\"Return label if any regex pattern matches the text.\"\"\"\n",
    "    for label, pat in patterns.items():\n",
    "        if re.search(pat, text):\n",
    "            return label\n",
    "    return \"\"\n",
    "\n",
    "PROCESS_PATTERNS = {\n",
    "    \"washed\": r\"\\bwashed\\b\",\n",
    "    \"natural\": r\"\\bnatural\\b\",\n",
    "    \"honey\": r\"\\bhoney\\b\",\n",
    "    \"anaerobic\": r\"\\banaerobic\\b\",\n",
    "}\n",
    "\n",
    "ROAST_PATTERNS = {\n",
    "    \"espresso\": r\"\\bespresso\\b|\\bespresso roast\\b\",\n",
    "    \"dark\": r\"\\bdark\\b|\\bdark roast\\b|\\bfrench\\b|\\bitalian\\b\",\n",
    "    \"medium\": r\"\\bmedium\\b|\\bmedium roast\\b|\\bfull city\\b|\\bcity\\+\\b\",\n",
    "    \"light\": r\"\\blight\\b|\\blight roast\\b|\\bcity\\b\",\n",
    "}\n",
    "\n",
    "NOTES_DICT = {\n",
    "    \"fruity\": [\"fruity\", \"berry\", \"citrus\", \"apple\", \"grape\", \"tropical\", \"mango\", \"pineapple\"],\n",
    "    \"floral\": [\"floral\", \"jasmine\", \"rose\"],\n",
    "    \"chocolate_nutty\": [\"chocolate\", \"cocoa\", \"nutty\", \"almond\", \"hazelnut\", \"caramel\"],\n",
    "    \"spicy\": [\"spice\", \"cinnamon\", \"clove\"],\n",
    "    \"sweet\": [\"sweet\", \"honey\", \"brown sugar\", \"vanilla\"],\n",
    "}\n",
    "\n",
    "def extract_notes_from_raw(text: str) -> str:\n",
    "    \"\"\"Return normalized notes string using keyword matching.\"\"\"\n",
    "    found = []\n",
    "    for label, kws in NOTES_DICT.items():\n",
    "        if any(kw in text for kw in kws):\n",
    "            found.append(label)\n",
    "    found = list(dict.fromkeys(found))\n",
    "    return \" \".join(found)\n",
    "\n",
    "\n",
    "# Apply HYBRID logic\n",
    "# - Use explicit columns first\n",
    "# - Fallback to raw_text if missing/invalid\n",
    "\n",
    "# Process (explicit -> normalize -> fallback)\n",
    "df[\"process_clean\"] = df[\"process\"].apply(normalize_process) if \"process\" in df.columns else \"\"\n",
    "missing_proc = df[\"process_clean\"].eq(\"\")\n",
    "df.loc[missing_proc, \"process_clean\"] = df.loc[missing_proc, \"raw_text\"].apply(\n",
    "    lambda t: extract_one(t, PROCESS_PATTERNS)\n",
    ")\n",
    "\n",
    "# Roast (explicit roast_level -> map -> fallback)\n",
    "df[\"roast_clean\"] = df[\"roast_level\"].apply(map_roast_level) if \"roast_level\" in df.columns else \"\"\n",
    "missing_roast = df[\"roast_clean\"].eq(\"\")\n",
    "df.loc[missing_roast, \"roast_clean\"] = df.loc[missing_roast, \"raw_text\"].apply(\n",
    "    lambda t: extract_one(t, ROAST_PATTERNS)\n",
    ")\n",
    "\n",
    "# Notes (explicit -> normalize -> fallback)\n",
    "df[\"notes_clean\"] = df[\"notes\"].apply(normalize_notes) if \"notes\" in df.columns else \"\"\n",
    "missing_notes = df[\"notes_clean\"].eq(\"\")\n",
    "df.loc[missing_notes, \"notes_clean\"] = df.loc[missing_notes, \"raw_text\"].apply(extract_notes_from_raw)\n",
    "\n",
    "# Origin (keep if exists)\n",
    "df[\"origin_clean\"] = df[\"origin\"].apply(normalize_origin) if \"origin\" in df.columns else \"\"\n",
    "\n",
    "# Keep a consistent downstream schema:\n",
    "# - process, roast, notes_str, origin (clean versions)\n",
    "df[\"process\"] = df[\"process_clean\"]\n",
    "df[\"roast\"] = df[\"roast_clean\"]\n",
    "df[\"notes_str\"] = df[\"notes_clean\"]\n",
    "df[\"origin\"] = df[\"origin_clean\"]\n",
    "\n",
    "# Quick checks\n",
    "print(\"Null/empty checks (count of empty strings):\")\n",
    "print({\n",
    "    \"process_empty\": int((df[\"process\"] == \"\").sum()),\n",
    "    \"roast_empty\": int((df[\"roast\"] == \"\").sum()),\n",
    "    \"notes_empty\": int((df[\"notes_str\"] == \"\").sum()),\n",
    "    \"origin_empty\": int((df[\"origin\"] == \"\").sum()) if \"origin\" in df.columns else None,\n",
    "})\n",
    "\n",
    "df[[\"raw_text\", \"process\", \"roast\", \"notes_str\", \"origin\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c379a97",
   "metadata": {},
   "source": [
    "## 3.5 Clean and Standarize `notes` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ecde1",
   "metadata": {},
   "source": [
    "Here we clean and standardize the notes column into a consistent notes_str, ready for TF-IDF tokens like notes_fruity, notes_floral, etc. In real datasets, notes can come as a list, a long free-text string, or already bucketed labels. If we keep it inconsistent, TF-IDF becomes noisy and rankings fluctuate. A clean notes_str makes the similarity layer more stable and the recommendations easier to reason about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82729f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notes_str empty count: 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>notes_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fruity, sweet</td>\n",
       "      <td>fruity sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>floral</td>\n",
       "      <td>floral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fruity, herbal</td>\n",
       "      <td>fruity herbal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chocolate, sweet</td>\n",
       "      <td>chocolate_nutty sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>caramel, floral, sweet</td>\n",
       "      <td>chocolate_nutty floral sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fruity, sweet</td>\n",
       "      <td>fruity sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fruity, sweet</td>\n",
       "      <td>fruity sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chocolate, fruity</td>\n",
       "      <td>chocolate_nutty fruity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chocolate, nutty, sweet</td>\n",
       "      <td>chocolate_nutty sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>caramel, nutty, sweet</td>\n",
       "      <td>chocolate_nutty sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>floral, herbal</td>\n",
       "      <td>floral herbal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      notes                     notes_str\n",
       "0             fruity, sweet                  fruity sweet\n",
       "1                    floral                        floral\n",
       "2                     sweet                         sweet\n",
       "3            fruity, herbal                 fruity herbal\n",
       "4                     sweet                         sweet\n",
       "5          chocolate, sweet         chocolate_nutty sweet\n",
       "6    caramel, floral, sweet  chocolate_nutty floral sweet\n",
       "7             fruity, sweet                  fruity sweet\n",
       "8             fruity, sweet                  fruity sweet\n",
       "9         chocolate, fruity        chocolate_nutty fruity\n",
       "10                  unknown                              \n",
       "11  chocolate, nutty, sweet         chocolate_nutty sweet\n",
       "12                  unknown                              \n",
       "13    caramel, nutty, sweet         chocolate_nutty sweet\n",
       "14           floral, herbal                 floral herbal"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes buckets\n",
    "NOTES_BUCKETS = {\n",
    "    \"fruity\": [\"fruity\", \"berry\", \"citrus\", \"apple\", \"grape\", \"tropical\", \"mango\", \"pineapple\"],\n",
    "    \"floral\": [\"floral\", \"jasmine\", \"rose\"],\n",
    "    \"chocolate_nutty\": [\"chocolate\", \"cocoa\", \"nutty\", \"almond\", \"hazelnut\", \"caramel\"],\n",
    "    \"spicy\": [\"spice\", \"cinnamon\", \"clove\"],\n",
    "    \"sweet\": [\"sweet\", \"honey\", \"brown sugar\", \"vanilla\"],\n",
    "    \"herbal\": [\"herbal\", \"tea\", \"green tea\", \"mint\", \"lemongrass\"],\n",
    "    \"woody\": [\"woody\", \"wood\", \"cedar\", \"oak\"]\n",
    "}\n",
    "\n",
    "CANONICAL = set(NOTES_BUCKETS.keys())\n",
    "\n",
    "def norm_str(x) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", str(x).strip().lower())\n",
    "\n",
    "def split_notes_string(s: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split a notes string that may use commas, slashes, pipes, semicolons.\n",
    "    Example: 'fruity/floral/chocolate_nutty' -> ['fruity','floral','chocolate_nutty']\n",
    "    \"\"\"\n",
    "\n",
    "    s = norm_str(s)\n",
    "    if not s:\n",
    "        return []\n",
    "    parts = re.split(r\"[,\\|/;]+\", s)\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "    return parts\n",
    "\n",
    "def map_to_bucket(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Map any token into our canonical buckets if possible.\n",
    "    - If token already one of canonical buckets => keep it\n",
    "    - Else find bucket by keyword matching\n",
    "    \"\"\"\n",
    "\n",
    "    t = norm_str(token).replace(\" \", \"_\")\n",
    "    if t in CANONICAL:\n",
    "        return t\n",
    "\n",
    "    t_space = norm_str(token)\n",
    "    # boundary match (kata utuh)\n",
    "    for bucket, kws in NOTES_BUCKETS.items():\n",
    "        for kw in kws:\n",
    "            if re.search(rf\"\\b{re.escape(kw)}\\b\", t_space):\n",
    "                return bucket\n",
    "    # Drop unknown token to reduce noise\n",
    "    return \"\"\n",
    "\n",
    "def normalize_notes_to_str(val) -> str:\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "    - list: ['citrus','jasmine']\n",
    "    - string: 'citrus, jasmine'\n",
    "    - bucketed string: 'fruity/floral/chocolate_nutty'\n",
    "    Output:\n",
    "    - 'fruity floral' (space-separated buckets, deduped)\n",
    "    \"\"\"\n",
    "    if val is None or (isinstance(val, float) and pd.isna(val)):\n",
    "        return \"\"\n",
    "\n",
    "    # If list-like\n",
    "    if isinstance(val, list):\n",
    "        tokens = [norm_str(x) for x in val if x is not None and str(x).strip()]\n",
    "    else:\n",
    "        # If it’s a string representation of a list: \"['citrus', 'jasmine']\"\n",
    "        s = norm_str(val)\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            # very light parse: remove brackets and quotes\n",
    "            s = s.strip(\"[]\")\n",
    "            s = s.replace('\"', \"\").replace(\"'\", \"\")\n",
    "            tokens = split_notes_string(s)\n",
    "        else:\n",
    "            tokens = split_notes_string(s)\n",
    "\n",
    "    # Map to canonical buckets\n",
    "    buckets = []\n",
    "    for tok in tokens:\n",
    "        b = map_to_bucket(tok)\n",
    "        if b:\n",
    "            buckets.append(b)\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    buckets = list(dict.fromkeys(buckets))\n",
    "\n",
    "    return \" \".join(buckets)\n",
    "\n",
    "# Apply\n",
    "df[\"notes_str\"] = df[\"notes\"].apply(normalize_notes_to_str)\n",
    "\n",
    "# Quick checks\n",
    "print(\"notes_str empty count:\", int((df[\"notes_str\"] == \"\").sum()))\n",
    "df[[\"notes\", \"notes_str\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf5bc3",
   "metadata": {},
   "source": [
    "## 3.6 Create `bean_type` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41482b",
   "metadata": {},
   "source": [
    "We explicitly define bean_type as a structured feature because it represents one of the most fundamental decision factors in coffee selection. For many users, the difference between arabica and robusta is not just technical—it directly affects flavor expectation, caffeine level, and overall drinking experience. By extracting bean_type into a dedicated column, we give the recommender a clear, explainable signal that can later be used for ranking boosts, penalties, or user preference matching, instead of relying purely on noisy free-text similarity.\n",
    "\n",
    "From a system design perspective, this also keeps the recommendation logic modular. Even if bean_type is not heavily weighted today, having it as a first-class feature allows us to evolve the ranking logic (for example, “prefer arabica for filter drinkers”) without refactoring the entire pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25329e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_bean_type(text: str):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    s = str(text).lower()\n",
    "    has_arabica = \"arabica\" in s\n",
    "    has_robusta = \"robusta\" in s\n",
    "    if has_arabica and has_robusta:\n",
    "        return \"arabica_robusta_blend\"\n",
    "    if has_arabica:\n",
    "        return \"arabica\"\n",
    "    if has_robusta:\n",
    "        return \"robusta\"\n",
    "    return None\n",
    "\n",
    "if \"bean_type\" not in df.columns:\n",
    "    df[\"bean_type\"] = df[\"raw_text\"].apply(infer_bean_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f07cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None 'arabica' 'robusta']\n",
      "\n",
      "\n",
      "bean_type\n",
      "arabica    173\n",
      "robusta     95\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "0         None\n",
      "1         None\n",
      "2         None\n",
      "3         None\n",
      "4         None\n",
      "        ...   \n",
      "609    robusta\n",
      "610    arabica\n",
      "611    robusta\n",
      "612       None\n",
      "613       None\n",
      "Name: bean_type, Length: 614, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check\n",
    "print(df[\"bean_type\"].unique())\n",
    "print(\"\\n\")\n",
    "print(df[\"bean_type\"].value_counts())\n",
    "print(\"\\n\")\n",
    "print(df[\"bean_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc2215",
   "metadata": {},
   "source": [
    "The large number of None values is expected and normal for marketplace data. In real product listings, sellers often do not explicitly state the bean type, especially when it is assumed (e.g., many specialty coffees default to arabica and don’t bother mentioning it). Some listings focus more on origin, roast level, or flavor notes, leaving bean composition implicit.\n",
    "\n",
    "This means None here does not indicate a data quality failure. It simply reflects that the information is not observable from text, and forcing a guess would introduce noise and false confidence. From an industry standpoint, it is better to leave a feature unknown than to hallucinate a value that could mislead downstream logic.\n",
    "\n",
    "**None is completely safe and intentional in this setup.**\n",
    "\n",
    "In our pipeline, bean_type is used as an optional structured signal, not a hard requirement. When it is present, it can contribute a boost during reranking (e.g., matching user preference). When it is missing, the system simply falls back to other strong signals such as TF-IDF similarity, process, roast level, and flavor notes.\n",
    "\n",
    "Crucially, bean_type is not a mandatory input for TF-IDF vectorization, so missing values do not break modeling, degrade embeddings, or skew similarity scores. Instead, this design preserves robustness: the recommender remains stable even when structured attributes are incomplete—which is exactly what we want in a real production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f4158",
   "metadata": {},
   "source": [
    "## 3.7 Create `match_text` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c736940",
   "metadata": {},
   "source": [
    "In this step we build a single final text field called match_text. It combines:\n",
    "- marketplace text: name_clean + desc_clean\n",
    "- tructured tokens: process_{...}, roast_{...}, bean_{...}, notes_{...}\n",
    "- optional guardrail tags: tag_house_blend, tag_blend\n",
    "- origin_{...} if origin is clean\n",
    "\n",
    "This makes TF-IDF matching more consistent because both user queries and products speak the same “token language.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd7bcf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_clean</th>\n",
       "      <th>desc_clean</th>\n",
       "      <th>process</th>\n",
       "      <th>roast</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>notes_str</th>\n",
       "      <th>origin</th>\n",
       "      <th>match_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candy apple espresso roast instinct roastery 2...</td>\n",
       "      <td>50 toraja washed 20 colombia sequoias watermel...</td>\n",
       "      <td>washed</td>\n",
       "      <td>espresso</td>\n",
       "      <td>None</td>\n",
       "      <td>fruity sweet</td>\n",
       "      <td>colombia, toraja, flores</td>\n",
       "      <td>candy apple espresso roast instinct roastery 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ethiopia tima washed instinct roastery 150 gram</td>\n",
       "      <td>region guji process washed variety 74110 altit...</td>\n",
       "      <td>washed</td>\n",
       "      <td>light</td>\n",
       "      <td>None</td>\n",
       "      <td>floral</td>\n",
       "      <td>ethiopia</td>\n",
       "      <td>ethiopia tima washed instinct roastery 150 gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>espresso roast kenya tatu instinct roastery 20...</td>\n",
       "      <td>process natural region kiambu county farm tatu...</td>\n",
       "      <td>washed</td>\n",
       "      <td>espresso</td>\n",
       "      <td>None</td>\n",
       "      <td>sweet</td>\n",
       "      <td>kenya</td>\n",
       "      <td>espresso roast kenya tatu instinct roastery 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethiopia sidama baturo instinct roastery 150 gram</td>\n",
       "      <td>process anaerobic natural variety 74158 region...</td>\n",
       "      <td>natural</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>fruity herbal</td>\n",
       "      <td>ethiopia</td>\n",
       "      <td>ethiopia sidama baturo instinct roastery 150 g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colombia eliecer ordez instinct roastery 150 gram</td>\n",
       "      <td>process washed variety pink bourbon region hui...</td>\n",
       "      <td>washed</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>sweet</td>\n",
       "      <td>colombia</td>\n",
       "      <td>colombia eliecer ordez instinct roastery 150 g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name_clean  \\\n",
       "0  candy apple espresso roast instinct roastery 2...   \n",
       "1    ethiopia tima washed instinct roastery 150 gram   \n",
       "2  espresso roast kenya tatu instinct roastery 20...   \n",
       "3  ethiopia sidama baturo instinct roastery 150 gram   \n",
       "4  colombia eliecer ordez instinct roastery 150 gram   \n",
       "\n",
       "                                          desc_clean  process     roast  \\\n",
       "0  50 toraja washed 20 colombia sequoias watermel...   washed  espresso   \n",
       "1  region guji process washed variety 74110 altit...   washed     light   \n",
       "2  process natural region kiambu county farm tatu...   washed  espresso   \n",
       "3  process anaerobic natural variety 74158 region...  natural             \n",
       "4  process washed variety pink bourbon region hui...   washed             \n",
       "\n",
       "  bean_type      notes_str                    origin  \\\n",
       "0      None   fruity sweet  colombia, toraja, flores   \n",
       "1      None         floral                  ethiopia   \n",
       "2      None          sweet                     kenya   \n",
       "3      None  fruity herbal                  ethiopia   \n",
       "4      None          sweet                  colombia   \n",
       "\n",
       "                                          match_text  \n",
       "0  candy apple espresso roast instinct roastery 2...  \n",
       "1  ethiopia tima washed instinct roastery 150 gra...  \n",
       "2  espresso roast kenya tatu instinct roastery 20...  \n",
       "3  ethiopia sidama baturo instinct roastery 150 g...  \n",
       "4  colombia eliecer ordez instinct roastery 150 g...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_token(x) -> str:\n",
    "    \"\"\"\n",
    "    Make a safe token chunk:\n",
    "    - handle NaN/None\n",
    "    - lowercase\n",
    "    - replace spaces with underscore\n",
    "    - remove weird punctuation (keep letters, numbers, underscore)\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = str(x).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def build_match_text(row) -> str:\n",
    "    parts = []\n",
    "\n",
    "    # Base text\n",
    "    base_name = row.get(\"name_clean\", \"\")\n",
    "    base_desc = row.get(\"desc_clean\", \"\")\n",
    "    parts.append(base_name)\n",
    "    parts.append(base_desc)\n",
    "\n",
    "    # Structured tokens (only if exist)\n",
    "    proc = clean_token(row.get(\"process\"))\n",
    "    if proc:\n",
    "        parts.append(f\"process_{proc}\")\n",
    "\n",
    "    roast = clean_token(row.get(\"roast\"))\n",
    "    if roast:\n",
    "        parts.append(f\"roast_{roast}\")\n",
    "\n",
    "    bean = clean_token(row.get(\"bean_type\"))\n",
    "    if bean:\n",
    "        parts.append(f\"bean_{bean}\")\n",
    "\n",
    "    notes_str = clean_token(row.get(\"notes_str\"))\n",
    "    # Give prefix notes_ to make it token-based\n",
    "    if notes_str:\n",
    "        parts.append(f\"notes_{notes_str}\")\n",
    "\n",
    "    # Tag flags (guardrails/extra signals)\n",
    "    if bool(row.get(\"is_house_blend\", False)):\n",
    "        parts.append(\"tag_house_blend\")\n",
    "    if bool(row.get(\"is_blend\", False)):\n",
    "        parts.append(\"tag_blend\")\n",
    "\n",
    "    # Origin token\n",
    "    origin = clean_token(row.get(\"origin\"))\n",
    "    if origin:\n",
    "        parts.append(f\"origin_{origin}\")\n",
    "\n",
    "    # Join and strip\n",
    "    return \" \".join([p for p in parts if p]).strip()\n",
    "\n",
    "df[\"match_text\"] = df.apply(build_match_text, axis=1)\n",
    "\n",
    "# Quick check\n",
    "df[[\"name_clean\", \"desc_clean\", \"process\", \"roast\", \"bean_type\", \"notes_str\", \"origin\", \"match_text\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46538aa9",
   "metadata": {},
   "source": [
    "## 3.8 Quality Check before Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12bcd7",
   "metadata": {},
   "source": [
    "In this QC step, we verify that the Feature Engineering output from the updated dataset is still consistent, valid, and safe for TF-IDF similarity and the reranking layer. Since the data changed (more rows, new patterns, different seller wording), QC acts as the last guardrail to catch silent issues—like empty match_text, unexpected values in process/roast, or overly-triggered flags (capsule/tools) due to noisy keywords. In practice, this is what keeps a recommender reliable when the dataset grows and evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d66118ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC 1: Shape check\n",
      "\n",
      "Rows, Cols: (614, 24)\n",
      "Duplicate rows (subset=['source', 'name', 'price']): 1\n"
     ]
    }
   ],
   "source": [
    "# Shape check\n",
    "print(\"QC 1: Shape check\\n\")\n",
    "print(\"Rows, Cols:\", df.shape)\n",
    "\n",
    "# Duplicates check (based on key identity columns)\n",
    "key_cols = [c for c in [\"source\", \"name\", \"price\"] if c in df.columns]\n",
    "if len(key_cols) >= 2:\n",
    "    dup_count = df.duplicated(subset=key_cols).sum()\n",
    "    print(f\"Duplicate rows (subset={key_cols}):\", int(dup_count))\n",
    "else:\n",
    "    print(\"Skip duplicate check (not enough key columns).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a06cdaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC 2: Missing rate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_na_rate</th>\n",
       "      <th>empty_string_rate</th>\n",
       "      <th>total_effective_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bean_type</th>\n",
       "      <td>0.563518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273616</td>\n",
       "      <td>0.273616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roast</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154723</td>\n",
       "      <td>0.154723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes_str</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096091</td>\n",
       "      <td>0.096091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           missing_na_rate  empty_string_rate  total_effective_missing\n",
       "bean_type         0.563518           0.000000                 0.563518\n",
       "process           0.000000           0.273616                 0.273616\n",
       "roast             0.000000           0.154723                 0.154723\n",
       "notes_str         0.000000           0.096091                 0.096091\n",
       "notes             0.000000           0.000000                 0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes == 'unknown' count: 59\n"
     ]
    }
   ],
   "source": [
    "# Missing rate\n",
    "print(\"QC 2: Missing rate\")\n",
    "qc_cols = [c for c in [\"process\", \"roast\", \"notes\", \"notes_str\", \"bean_type\"] if c in df.columns]\n",
    "missing_report = {}\n",
    "\n",
    "for c in qc_cols:\n",
    "    # Treat \"\", None, NaN as missing\n",
    "    miss = df[c].isna().mean()\n",
    "    empty = (df[c].astype(str).str.strip() == \"\").mean()\n",
    "    missing_report[c] = {\n",
    "        \"missing_na_rate\": miss,\n",
    "        \"empty_string_rate\": empty,\n",
    "        \"total_effective_missing\": max(miss, empty)\n",
    "    }\n",
    "\n",
    "missing_df = pd.DataFrame(missing_report).T.sort_values(\"total_effective_missing\", ascending=False)\n",
    "display(missing_df)\n",
    "\n",
    "# how many \"unknown\" after hybrid/fallback?\n",
    "if \"notes\" in df.columns:\n",
    "    unknown_count = (df[\"notes\"].astype(str).str.lower().str.strip() == \"unknown\").sum()\n",
    "    print(\"Notes == 'unknown' count:\", int(unknown_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba1a97f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC 3: Value sanity\n",
      "\n",
      "Unexpected process values      : ['']\n",
      "Unexpected roast values        : ['']\n",
      "Unexpected bean_type values    : []\n"
     ]
    }
   ],
   "source": [
    "# Value sanity\n",
    "print(\"QC 3: Value sanity\\n\")\n",
    "\n",
    "allowed_process = {None, \"washed\", \"natural\", \"honey\", \"anaerobic\"}\n",
    "allowed_roast   = {None, \"light\", \"medium\", \"dark\", \"espresso\"}\n",
    "allowed_bean    = {None, \"arabica\", \"robusta\", \"arabica_robusta_blend\"}\n",
    "\n",
    "def unexpected_values(series: pd.Series, allowed: set):\n",
    "    vals = series.dropna().astype(str).str.strip().unique().tolist()\n",
    "    bad = [v for v in vals if v not in {x for x in allowed if x is not None}]\n",
    "    return bad\n",
    "\n",
    "if \"process\" in df.columns:\n",
    "    bad_proc = unexpected_values(df[\"process\"], allowed_process)\n",
    "    print(\"Unexpected process values      :\", bad_proc[:20])\n",
    "\n",
    "if \"roast\" in df.columns:\n",
    "    bad_roast = unexpected_values(df[\"roast\"], allowed_roast)\n",
    "    print(\"Unexpected roast values        :\", bad_roast[:20])\n",
    "\n",
    "if \"bean_type\" in df.columns:\n",
    "    bad_bean = unexpected_values(df[\"bean_type\"], allowed_bean)\n",
    "    print(\"Unexpected bean_type values    :\", bad_bean[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9359cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC 4: match_text non-empty\n",
      "\n",
      "match_text empty count: 0\n",
      "\n",
      "Sample 5 rows (to eyeball tokens):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>match_text</th>\n",
       "      <th>process</th>\n",
       "      <th>roast</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>notes_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>kopi arabika bali kintamani natural arabica co...</td>\n",
       "      <td>kopi arabika bali kintamani natural arabica co...</td>\n",
       "      <td>natural</td>\n",
       "      <td>medium</td>\n",
       "      <td>arabica</td>\n",
       "      <td>fruity sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>kopi arabika lintong sumatra arabica coffee be...</td>\n",
       "      <td>kopi arabika lintong sumatra arabica coffee be...</td>\n",
       "      <td>washed</td>\n",
       "      <td>dark</td>\n",
       "      <td>arabica</td>\n",
       "      <td>chocolate_nutty fruity sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>kopi arabika kamojang green apple 1 kg bijibub...</td>\n",
       "      <td>kopi arabika kamojang green apple 1 kg bijibub...</td>\n",
       "      <td>washed</td>\n",
       "      <td>medium</td>\n",
       "      <td>None</td>\n",
       "      <td>fruity herbal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>arutala kopi robusta jawa java coffee indonesi...</td>\n",
       "      <td>arutala kopi robusta jawa java coffee indonesi...</td>\n",
       "      <td></td>\n",
       "      <td>dark</td>\n",
       "      <td>robusta</td>\n",
       "      <td>chocolate_nutty sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sulawesi tana luwu 200gr single origin special...</td>\n",
       "      <td>sulawesi tana luwu 200gr single origin special...</td>\n",
       "      <td>honey</td>\n",
       "      <td>medium</td>\n",
       "      <td>None</td>\n",
       "      <td>fruity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "350  kopi arabika bali kintamani natural arabica co...   \n",
       "377  kopi arabika lintong sumatra arabica coffee be...   \n",
       "163  kopi arabika kamojang green apple 1 kg bijibub...   \n",
       "609  arutala kopi robusta jawa java coffee indonesi...   \n",
       "132  sulawesi tana luwu 200gr single origin special...   \n",
       "\n",
       "                                            match_text  process   roast  \\\n",
       "350  kopi arabika bali kintamani natural arabica co...  natural  medium   \n",
       "377  kopi arabika lintong sumatra arabica coffee be...   washed    dark   \n",
       "163  kopi arabika kamojang green apple 1 kg bijibub...   washed  medium   \n",
       "609  arutala kopi robusta jawa java coffee indonesi...             dark   \n",
       "132  sulawesi tana luwu 200gr single origin special...    honey  medium   \n",
       "\n",
       "    bean_type                     notes_str  \n",
       "350   arabica                  fruity sweet  \n",
       "377   arabica  chocolate_nutty fruity sweet  \n",
       "163      None                 fruity herbal  \n",
       "609   robusta         chocolate_nutty sweet  \n",
       "132      None                        fruity  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Non-empty match_text\n",
    "print(\"QC 4: match_text non-empty\\n\")\n",
    "\n",
    "if \"match_text\" in df.columns:\n",
    "    match_empty = (df[\"match_text\"].isna() | (df[\"match_text\"].astype(str).str.strip() == \"\")).sum()\n",
    "    print(\"match_text empty count:\", int(match_empty))\n",
    "\n",
    "    print(\"\\nSample 5 rows (to eyeball tokens):\")\n",
    "    sample_cols = [c for c in [\"name\", \"match_text\", \"process\", \"roast\", \"bean_type\", \"notes_str\"] if c in df.columns]\n",
    "    display(df[sample_cols].sample(5, random_state=42))\n",
    "else:\n",
    "    print(\"ERROR: match_text column not found. TF-IDF step will break.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c2122f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC 5: Flag distribution\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_count</th>\n",
       "      <th>true_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_merch_tools</th>\n",
       "      <td>402.0</td>\n",
       "      <td>0.654723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_liquid</th>\n",
       "      <td>217.0</td>\n",
       "      <td>0.353420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_blend</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.146580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_house_blend</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.016287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_capsule</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.013029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                true_count  true_rate\n",
       "is_merch_tools       402.0   0.654723\n",
       "is_liquid            217.0   0.353420\n",
       "is_blend              90.0   0.146580\n",
       "is_house_blend        10.0   0.016287\n",
       "is_capsule             8.0   0.013029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flag distribution\n",
    "print(\"QC 5: Flag distribution\\n\")\n",
    "flag_cols = [c for c in [\"is_house_blend\", \"is_blend\", \"is_capsule\", \"is_liquid\", \"is_merch_tools\"] if c in df.columns]\n",
    "\n",
    "if flag_cols:\n",
    "    dist = {}\n",
    "    for c in flag_cols:\n",
    "        dist[c] = {\n",
    "            \"true_count\": int((df[c] == True).sum()),\n",
    "            \"true_rate\": float((df[c] == True).mean())\n",
    "        }\n",
    "    dist_df = pd.DataFrame(dist).T.sort_values(\"true_rate\", ascending=False)\n",
    "    display(dist_df)\n",
    "else:\n",
    "    print(\"No flag columns found. (Skip)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae7b9f",
   "metadata": {},
   "source": [
    "---\n",
    "**Final Check Conclusion**\n",
    "\n",
    "---\n",
    "\n",
    "Overall, this updated FE output looks production-safe for the next steps (TF-IDF retrieval + reranking). The core “output contract” is intact: the dataset shape is reasonable, match_text is never empty, and your categorical fields are not drifting outside the allowed label set.\n",
    "\n",
    "Three takeaways matter most:\n",
    "\n",
    "1. The dataset has 614 rows and 24 cols and we only have 1 duplicate when checking source + name + price. That’s not a serious issue because marketplace data often contains repeated listings, and we have dropped this duplicated data.\n",
    "\n",
    "2. Missing/empty values exist, but they’re not blockers—they’re mostly a data reality:\n",
    "    - process and roast are not NaN, but they have empty strings (~27% and ~15%). That suggests the “explicit” columns aren’t always filled. Our pipeline is still fine because it can fall back to raw text signals and still build a usable match_text.\n",
    "    - bean_type has a high missing rate (~56%). That’s expected: many product listings simply don’t state arabica/robusta. This won’t break TF-IDF—missing just means we don’t inject the bean_{...} token for those rows.\n",
    "    - notes == \"unknown\" appears 59 times. This is also reasonable: “unknown” is better than forcing a wrong guess. The key is to treat “unknown” consistently (typically: don’t convert it into notes tokens).\n",
    "\n",
    "3. Flag distribution gives business insight and one soft warning:\n",
    "    - is_merch_tools firing on 65% of rows is unusually high. This likely means our tools/merch keyword list is too aggressive (e.g., the word “filter” shows up in “filter coffee beans” but gets interpreted as a brewing tool). This won’t crash anything, but it can hurt relevance if our hard filters or penalties start eliminating too many valid beans.\n",
    "    - is_liquid at 35% is plausible (RTD is common).\n",
    "    - is_capsule and is_house_blend are small (1–2%), which looks realistic.\n",
    "\n",
    "Final takeaway: the FE pipeline is technically solid and ready to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcdbe56",
   "metadata": {},
   "source": [
    "## 3.9 Export FE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7081dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"engineered_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39100e4",
   "metadata": {},
   "source": [
    "# iv. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5fd2d6",
   "metadata": {},
   "source": [
    "---\n",
    "**Why we use TF-IDF fot Product Matching**\n",
    "\n",
    "In this project, the core task is text-to-text matching: we take a user’s preference or query and retrieve products that are most relevant, not predict a numeric value or a class label. This is fundamentally an information retrieval / ranking problem.\n",
    "\n",
    "TF-IDF is a strong fit because it is:\n",
    "\n",
    "- A reliable retrieval baseline: For product titles, short descriptions, categories, and tags, TF-IDF often delivers surprisingly solid relevance.\n",
    "\n",
    "- Interpretable: We can explain why an item is retrieved (high-weight terms overlap), which is valuable for business stakeholders.\n",
    "\n",
    "- Efficient and deployment-friendly: Fast to train and fast to serve, no GPU dependency, stable in production.\n",
    "\n",
    "- Label-free: It does not require query–product relevance labels, which we often do not have in early-stage systems.\n",
    "\n",
    "In short, TF-IDF aligns with the nature of the problem: retrieve and rank, not “predict a label”.\n",
    "\n",
    "---\n",
    "**Why we do not use other models**\n",
    "\n",
    "Supervised models such as Logistic Regression, Random Forest, or XGBoost are designed for prediction tasks with clear labels, whereas this project focuses on retrieving and ranking products based on textual relevance rather than predicting a class or value. Without reliable ground truth indicating which products should match a given query, applying such models would introduce artificial assumptions and unnecessary complexity, potentially producing results that look sophisticated but do not actually solve the business problem. A text-based retrieval approach like TF-IDF aligns more naturally with the problem structure and remains easier to interpret and validate from a business perspective.\n",
    "\n",
    "---\n",
    "**Why embeddings are not required at this stage**\n",
    "\n",
    "While embeddings can capture deeper semantic relationships, their added complexity is not yet justified for the current scope of this project. The vocabulary used in user preferences and product descriptions still overlaps sufficiently, allowing TF-IDF to capture relevance effectively without additional infrastructure, higher computational costs, or reliance on external models. By starting with TF-IDF as a strong baseline, we maintain a lightweight and explainable solution, while keeping the option open to introduce embeddings later if semantic gaps become a recurring limitation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26937af2",
   "metadata": {},
   "source": [
    "## 4.1 Query Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3caba12",
   "metadata": {},
   "source": [
    "We make a function to converts the structured user preferences (decision rule output in key–value form) into a standardized query string whose tokens are aligned with the product match_text tokens. The resulting query is then used as TF-IDF input to compute similarity scores and rank the most relevant products.\n",
    "\n",
    "It strongly matters because TF-IDF operates on text, not dictionaries/JSON, so we need a consistent “shared language” between user preferences and the product catalog (e.g., roast_dark, bean_arabica, notes_fruity). A standardized query improves retrieval stability, makes debugging easier, and supports production-friendly behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8fcc687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query_text(user_profile: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Expected keys:\n",
    "    - roast_level: \"light\"|\"medium\"|\"dark\"|None\n",
    "    - process_preference: \"washed\"|\"natural\"|\"honey\"|\"anaerobic\"|\"any\"|None\n",
    "    - bean_pref: \"arabica\"|\"robusta\"|\"any\"|None\n",
    "    - flavor_direction: e.g. \"fruity\", \"floral\", \"chocolate_nutty\", \"spicy\", \"sweet\" (or list)\n",
    "    - acidity_level: optional; we can map to note proxies if you want\n",
    "    \"\"\"\n",
    "\n",
    "    tokens: List[str] = []\n",
    "\n",
    "    roast = user_profile.get(\"roast_level\")\n",
    "    if roast and roast != \"any\":\n",
    "        tokens.append(f\"roast_{roast}\")\n",
    "\n",
    "    proc = user_profile.get(\"process_preference\")\n",
    "    if proc and proc != \"any\":\n",
    "        tokens.append(f\"process_{proc}\")\n",
    "\n",
    "    bean = user_profile.get(\"bean_pref\")\n",
    "    if bean and bean != \"any\":\n",
    "        tokens.append(f\"bean_{bean}\")\n",
    "\n",
    "    # Flavor_direction could be str or list[str]\n",
    "    flavor = user_profile.get(\"flavor_direction\")\n",
    "    if isinstance(flavor, str) and flavor:\n",
    "        tokens.append(f\"notes_{flavor}\")\n",
    "    elif isinstance(flavor, list):\n",
    "        for f in flavor:\n",
    "            if f:\n",
    "                tokens.append(f\"notes_{f}\")\n",
    "\n",
    "    # Map acidity preference to note proxies\n",
    "    # This is a lightweight heuristic, not mandatory.\n",
    "    acidity = user_profile.get(\"acidity_level\")\n",
    "    if acidity == \"high\":\n",
    "        tokens.append(\"notes_fruity\")\n",
    "        tokens.append(\"notes_floral\")\n",
    "    elif acidity == \"low\":\n",
    "        tokens.append(\"notes_chocolate_nutty\")\n",
    "\n",
    "    # Join tokens into a compact query string\n",
    "    query = \" \".join(tokens).strip()\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3d48252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roast_light process_washed bean_arabica notes_fruity notes_floral notes_fruity notes_floral\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "\n",
    "# Create a sample user input\n",
    "sample_profile = {\n",
    "    \"roast_level\": \"light\",\n",
    "    \"process_preference\": \"washed\",\n",
    "    \"bean_pref\": \"arabica\",\n",
    "    \"flavor_direction\": [\"fruity\", \"floral\"],\n",
    "    \"acidity_level\": \"high\",\n",
    "}\n",
    "\n",
    "# Run query function\n",
    "query = build_query_text(sample_profile)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c497f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate tokens\n",
    "def build_query_text_dedup(user_profile: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    This function removes duplicate tokens from the constructed query \n",
    "    text while preserving their original order. It ensures that each \n",
    "    user preference contributes only once to the TF-IDF similarity \\\n",
    "    calculation.\n",
    "    \"\"\"\n",
    "\n",
    "    q = build_query_text(user_profile)\n",
    "    tokens = q.split()\n",
    "    tokens = list(dict.fromkeys(tokens))  # preserve order, remove duplicates\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c762c0",
   "metadata": {},
   "source": [
    "## 4.2 TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b0267",
   "metadata": {},
   "source": [
    "### Load Feature Engineered Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c11e5",
   "metadata": {},
   "source": [
    "We load the feature-engineered dataset (engineered_dataset.csv) and enforce a minimal column contract required for TF-IDF-based product matching. The match_text column is then standardized to remove missing values and ensure string type consistency so it is safe for vectorization.\n",
    "\n",
    "It's important because retrieval pipelines rely on a clear input data contract. Validating required columns early enables a fail-fast workflow and prevents hard-to-trace downstream errors (e.g., during TF-IDF fit/transform). Standardizing match_text is also critical because TF-IDF expects clean text input with no NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7fa7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load featured engineered dataset\n",
    "df_fe = pd.read_csv(\"engineered_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "139e6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>match_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candy apple espresso roast  instinct roastery ...</td>\n",
       "      <td>candy apple espresso roast instinct roastery 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ethiopia tima washed  instinct roastery  150 gram</td>\n",
       "      <td>ethiopia tima washed instinct roastery 150 gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>espresso roast kenya tatu  instinct roastery  ...</td>\n",
       "      <td>espresso roast kenya tatu instinct roastery 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethiopia sidama baturo  instinct roastery  150...</td>\n",
       "      <td>ethiopia sidama baturo instinct roastery 150 g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colombia eliecer ordez  instinct roastery  150...</td>\n",
       "      <td>colombia eliecer ordez instinct roastery 150 g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  candy apple espresso roast  instinct roastery ...   \n",
       "1  ethiopia tima washed  instinct roastery  150 gram   \n",
       "2  espresso roast kenya tatu  instinct roastery  ...   \n",
       "3  ethiopia sidama baturo  instinct roastery  150...   \n",
       "4  colombia eliecer ordez  instinct roastery  150...   \n",
       "\n",
       "                                          match_text  \n",
       "0  candy apple espresso roast instinct roastery 2...  \n",
       "1  ethiopia tima washed instinct roastery 150 gra...  \n",
       "2  espresso roast kenya tatu instinct roastery 20...  \n",
       "3  ethiopia sidama baturo instinct roastery 150 g...  \n",
       "4  colombia eliecer ordez instinct roastery 150 g...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the required columns\n",
    "required_cols = [\"source\", \"name\", \"price\", \"description\", \"match_text\"]\n",
    "missing = [c for c in required_cols if c not in df_fe.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in FE dataset: {missing}\")\n",
    "\n",
    "df_fe[\"match_text\"] = df_fe[\"match_text\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Quick sanity check\n",
    "print(df_fe.shape)\n",
    "df_fe[[\"name\", \"match_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee47800",
   "metadata": {},
   "source": [
    "### Fit TF-IDF on match_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ed788",
   "metadata": {},
   "source": [
    "This step converts the product match_text corpus into numeric TF-IDF vectors. The resulting TF-IDF matrix serves as the retrieval “index” used to compare user queries against products via cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb8a5a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (614, 8910)\n"
     ]
    }
   ],
   "source": [
    "# Defune the vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    token_pattern=r\"(?u)\\b\\w[\\w_]+\\b\"\n",
    ")\n",
    "\n",
    "# Define the TF-IDF matrix by fit_transform the vectorizer to match_text\n",
    "X_tfidf = vectorizer.fit_transform(df_fe[\"match_text\"])\n",
    "\n",
    "# Sanity check\n",
    "print(\"TF-IDF matrix shape:\", X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81cdcc8",
   "metadata": {},
   "source": [
    "### Build Query Text from User Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9c2a2",
   "metadata": {},
   "source": [
    "This cell runs a lightweight end-to-end check from user preferences to decision rules (build_profile) to profile dictionary output to query construction (build_query_text_dedup). The final output is a token-based query string aligned with product match_text, ready for TF-IDF and cosine similarity ranking.\n",
    "\n",
    "This acts as a small integration test to confirm there is no hidden format mismatch between components (user input, rule outputs, and query builder). Printing both user_profile and query_text makes it easy to validate that user intent is correctly translated into retrieval tokens that drive product ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5cab531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User profile: {'acidity_level': 'low', 'caffeine_tendency': 'medium', 'roast_level': 'medium', 'flavor_direction': 'fruity', 'process_preference': 'washed', 'brew_suitability': 'filter', 'bean_preference': 'arabica'}\n",
      "Query text: roast_medium process_washed notes_fruity notes_chocolate_nutty\n"
     ]
    }
   ],
   "source": [
    "# Example of user input\n",
    "user = UserPref(\n",
    "    stomach_sensitivity=\"high\",\n",
    "    caffeine_sensitivity=\"medium\",\n",
    "    time_of_day=\"morning\",\n",
    "    purpose=\"focus\",\n",
    "    flavor_direction=[\"fruity\", \"floral\"],  # bisa string atau list\n",
    "    brew_method=\"filter\",\n",
    ")\n",
    "\n",
    "profile_out = build_profile(user)\n",
    "\n",
    "# Take dictionary profile that will be used as a query\n",
    "user_profile = profile_out[\"profile\"] if \"profile\" in profile_out else profile_out\n",
    "\n",
    "query_text = build_query_text_dedup(user_profile)\n",
    "\n",
    "print(\"User profile:\", user_profile)\n",
    "print(\"Query text:\", query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba33c2c",
   "metadata": {},
   "source": [
    "### Transform Query and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60908d1",
   "metadata": {},
   "source": [
    "This process converts the user query into a TF-IDF vector, compute cosine similarity against all product vectors, and retrieve the Top-K most relevant products along with their similarity scores, because cosine similarity provides a numeric measure of contextual alignment between user preferences and product descriptions. This enables consistent, explainable ranking instead of arbitrary selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67b9e119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>costa rica  mirazu dcafetal espresso roast sin...</td>\n",
       "      <td>150000</td>\n",
       "      <td>costa rica tarrazu mirazu dcafetal black honey...</td>\n",
       "      <td>0.097683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>indonesia  gulang 2817 natural anaerobic  150g</td>\n",
       "      <td>150000</td>\n",
       "      <td>indonesia flores manggarai lot gulang 2817 nat...</td>\n",
       "      <td>0.086921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>114000</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>0.068407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>fugol coffee roasters</td>\n",
       "      <td>kopi arabika watermelon smash 100 gram natural...</td>\n",
       "      <td>81000</td>\n",
       "      <td>halal id32110016691860324 pirt308327301034727 ...</td>\n",
       "      <td>0.064859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>swargi roasters</td>\n",
       "      <td>mid grade espresso malt crema 100 arabica  200 gr</td>\n",
       "      <td>65000</td>\n",
       "      <td>malt crema beans yang diroasting khusus untuk ...</td>\n",
       "      <td>0.064742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>ethiopia yirgacheffe  arabica specialty coffee...</td>\n",
       "      <td>301500</td>\n",
       "      <td>ethiopia yirgacheffe  specialty coffee  collin...</td>\n",
       "      <td>0.063927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>a roastworks</td>\n",
       "      <td>black  gold espresso blend  a roastworks  biji...</td>\n",
       "      <td>245000</td>\n",
       "      <td>black  gold espresso blend brazil alto caparao...</td>\n",
       "      <td>0.062753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>yunnan mengzhu honey asd  filter specialty cof...</td>\n",
       "      <td>130000</td>\n",
       "      <td>yunnan mengzhu honey asd  filter specialty cof...</td>\n",
       "      <td>0.056469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>arutala coffee</td>\n",
       "      <td>arutala kopi vietnam central highland robusta ...</td>\n",
       "      <td>260900</td>\n",
       "      <td>kenapa arutala coffee dengan memiliki roastery...</td>\n",
       "      <td>0.053666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>arutala coffee</td>\n",
       "      <td>arutala kopi colombia decaf arabika 200 gram  ...</td>\n",
       "      <td>139900</td>\n",
       "      <td>kenapa arutala coffee dengan memiliki roastery...</td>\n",
       "      <td>0.053493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source  \\\n",
       "187  tatido coffee roasters   \n",
       "186  tatido coffee roasters   \n",
       "299        collins roasters   \n",
       "172   fugol coffee roasters   \n",
       "275         swargi roasters   \n",
       "301        collins roasters   \n",
       "236            a roastworks   \n",
       "288        collins roasters   \n",
       "586          arutala coffee   \n",
       "602          arutala coffee   \n",
       "\n",
       "                                                  name   price  \\\n",
       "187  costa rica  mirazu dcafetal espresso roast sin...  150000   \n",
       "186     indonesia  gulang 2817 natural anaerobic  150g  150000   \n",
       "299  bali karana madu honey anaerobic  collins roas...  114000   \n",
       "172  kopi arabika watermelon smash 100 gram natural...   81000   \n",
       "275  mid grade espresso malt crema 100 arabica  200 gr   65000   \n",
       "301  ethiopia yirgacheffe  arabica specialty coffee...  301500   \n",
       "236  black  gold espresso blend  a roastworks  biji...  245000   \n",
       "288  yunnan mengzhu honey asd  filter specialty cof...  130000   \n",
       "586  arutala kopi vietnam central highland robusta ...  260900   \n",
       "602  arutala kopi colombia decaf arabika 200 gram  ...  139900   \n",
       "\n",
       "                                           description  similarity  \n",
       "187  costa rica tarrazu mirazu dcafetal black honey...    0.097683  \n",
       "186  indonesia flores manggarai lot gulang 2817 nat...    0.086921  \n",
       "299  bali karana madu honey anaerobic  collins roas...    0.068407  \n",
       "172  halal id32110016691860324 pirt308327301034727 ...    0.064859  \n",
       "275  malt crema beans yang diroasting khusus untuk ...    0.064742  \n",
       "301  ethiopia yirgacheffe  specialty coffee  collin...    0.063927  \n",
       "236  black  gold espresso blend brazil alto caparao...    0.062753  \n",
       "288  yunnan mengzhu honey asd  filter specialty cof...    0.056469  \n",
       "586  kenapa arutala coffee dengan memiliki roastery...    0.053666  \n",
       "602  kenapa arutala coffee dengan memiliki roastery...    0.053493  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vec = vectorizer.transform([query_text])\n",
    "\n",
    "# Cosine similarity: (1 x N)\n",
    "similarity = cosine_similarity(q_vec, X_tfidf).ravel()\n",
    "\n",
    "# Take top-K\n",
    "top_n = 10\n",
    "top_idx = np.argsort(similarity)[::-1][:top_n]\n",
    "\n",
    "results = df_fe.loc[top_idx, [\"source\", \"name\", \"price\", \"description\"]].copy()\n",
    "results[\"similarity\"] = similarity[top_idx]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611aebe",
   "metadata": {},
   "source": [
    "The similarity column represents relative relevance scores (range 0–1). Higher values indicate stronger textual alignment with the query. These scores are not probabilities; they are meaningful only for ranking within the same query. Top-ranked products share important, high-weight tokens with the query (e.g., washed, fruity), making them more contextually suitable for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a72a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity stats:\n",
      "count    614.000000\n",
      "mean       0.014676\n",
      "std        0.015750\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.008372\n",
      "75%        0.022902\n",
      "max        0.097683\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "# Check small similarity distribution\n",
    "print(\"Similarity stats:\")\n",
    "print(pd.Series(similarity).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc9d3137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>match_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>costa rica  mirazu dcafetal espresso roast sin...</td>\n",
       "      <td>costa rica mirazu dcafetal espresso roast sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>indonesia  gulang 2817 natural anaerobic  150g</td>\n",
       "      <td>indonesia gulang 2817 natural anaerobic 150g i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>bali karana madu honey anaerobic collins roast...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "187  costa rica  mirazu dcafetal espresso roast sin...   \n",
       "186     indonesia  gulang 2817 natural anaerobic  150g   \n",
       "299  bali karana madu honey anaerobic  collins roas...   \n",
       "\n",
       "                                            match_text  \n",
       "187  costa rica mirazu dcafetal espresso roast sing...  \n",
       "186  indonesia gulang 2817 natural anaerobic 150g i...  \n",
       "299  bali karana madu honey anaerobic collins roast...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "# Check top 3 match and the match_text\n",
    "debug_cols = [\"name\", \"match_text\"]\n",
    "df_fe.loc[top_idx[:3], debug_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b6841f",
   "metadata": {},
   "source": [
    "## 4.3 Ranking and Penalty Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a6dfb",
   "metadata": {},
   "source": [
    "In the ranking and penalty layer, the goal is no longer to find products that are merely textually similar, but to refine the recommendation order so it makes sense in real usage. TF-IDF and cosine similarity provide a strong relevance baseline based on product descriptions, but in real business scenarios, textual similarity alone is rarely sufficient. This layer allows us to adjust the ranking using practical considerations that are not always captured in text, such as user constraints, consumption context, or suitability rules (e.g., sensitivity, time of use, or brewing method). The penalty mechanism does not discard relevant products outright, but softly deprioritizes options that are less appropriate, ensuring the final recommendations are not just linguistically relevant, but context-aware and user-aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98578d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns of ranking and penalty\n",
    "rank_cols = [\n",
    "    \"is_capsule\", \"is_liquid\", \"is_merch_tools\", \"is_house_blend\", \"is_blend\",\n",
    "    \"process\", \"roast\", \"bean_type\", \"notes\"\n",
    "]\n",
    "\n",
    "# Sanity check\n",
    "[c for c in rank_cols if c not in df_fe.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a1e2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scoring config\n",
    "ranking_config = {\n",
    "    # Hard filters (if True, throw away)\n",
    "    \"hard_filter\": {\n",
    "        \"exclude_merch_tools\": True,\n",
    "        \"exclude_liquid\": True,\n",
    "    },\n",
    "\n",
    "    # Penalties\n",
    "    \"penalty\": {\n",
    "        \"capsule\": 0.08,\n",
    "        \"house_blend\": 0.03,\n",
    "        \"blend\": 0.015,\n",
    "    },\n",
    "    \n",
    "    # Boosts\n",
    "    \"boost\": {\n",
    "        \"process_match\": 0.015,\n",
    "        \"roast_match\": 0.010,\n",
    "        \"bean_match\": 0.010,\n",
    "        \"notes_match\": 0.008,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d782027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rerank function\n",
    "def rerank_candidates(\n",
    "    candidate_df: pd.DataFrame,\n",
    "    user_profile: Dict[str, Any],\n",
    "    config: Dict[str, Any],\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function performs post-ranking on TF-IDF candidates. It starts \n",
    "    from the base similarity score and adjusts it using business rules: \n",
    "    hard filters (remove items), penalties (softly demote), and boosts \n",
    "    (promote items that match user preferences). The final output is \n",
    "    sorted by final_score\n",
    "    \"\"\"\n",
    "\n",
    "    df = candidate_df.copy()\n",
    "\n",
    "    # Hard filter\n",
    "    if config[\"hard_filter\"].get(\"exclude_merch_tools\", False) and \"is_merch_tools\" in df.columns:\n",
    "        df = df[df[\"is_merch_tools\"] == False]\n",
    "    if config[\"hard_filter\"].get(\"exclude_liquid\", False) and \"is_liquid\" in df.columns:\n",
    "        df = df[df[\"is_liquid\"] == False]\n",
    "\n",
    "    # If the filter output is none, fallback: skip filtering step\n",
    "    if df.empty:\n",
    "        df = candidate_df.copy()\n",
    "\n",
    "    # Start from similarity\n",
    "    df[\"final_score\"] = df[\"similarity\"].astype(float)\n",
    "\n",
    "    # Apply penalties\n",
    "    pen = config[\"penalty\"]\n",
    "\n",
    "    if \"is_capsule\" in df.columns:\n",
    "        df.loc[df[\"is_capsule\"] == True, \"final_score\"] -= pen.get(\"capsule\", 0.0)\n",
    "\n",
    "    if \"is_house_blend\" in df.columns:\n",
    "        df.loc[df[\"is_house_blend\"] == True, \"final_score\"] -= pen.get(\"house_blend\", 0.0)\n",
    "\n",
    "    if \"is_blend\" in df.columns:\n",
    "        df.loc[df[\"is_blend\"] == True, \"final_score\"] -= pen.get(\"blend\", 0.0)\n",
    "\n",
    "    # Apply boosts (match with user_profile)\n",
    "    boo = config[\"boost\"]\n",
    "\n",
    "    # Process match\n",
    "    proc = user_profile.get(\"process_preference\")\n",
    "    if proc and proc != \"any\" and \"process\" in df.columns:\n",
    "        df.loc[df[\"process\"] == proc, \"final_score\"] += boo.get(\"process_match\", 0.0)\n",
    "\n",
    "    # Roast match\n",
    "    roast = user_profile.get(\"roast_level\")\n",
    "    if roast and roast != \"any\" and \"roast\" in df.columns:\n",
    "        df.loc[df[\"roast\"] == roast, \"final_score\"] += boo.get(\"roast_match\", 0.0)\n",
    "\n",
    "    # Bean match\n",
    "    bean = user_profile.get(\"bean_pref\") or user_profile.get(\"bean_preference\")\n",
    "    if bean and bean != \"any\" and \"bean_type\" in df.columns:\n",
    "        # Dataset bean_type can be \"arabica\" / \"robusta\" / \"arabica_robusta_blend\"\n",
    "        df.loc[df[\"bean_type\"] == bean, \"final_score\"] += boo.get(\"bean_match\", 0.0)\n",
    "\n",
    "    # Notes match\n",
    "    flavor = user_profile.get(\"flavor_direction\")\n",
    "    if flavor and \"notes\" in df.columns:\n",
    "        if isinstance(flavor, str):\n",
    "            flavor_set = {flavor}\n",
    "        else:\n",
    "            flavor_set = set([f for f in flavor if f])\n",
    "\n",
    "        def notes_has_overlap(notes_val) -> bool:\n",
    "            if pd.isna(notes_val):\n",
    "                return False\n",
    "            # If the result is saved in string\n",
    "            s = str(notes_val).lower()\n",
    "            return any(f in s for f in flavor_set)\n",
    "\n",
    "        overlap_mask = df[\"notes\"].apply(notes_has_overlap)\n",
    "        df.loc[overlap_mask, \"final_score\"] += boo.get(\"notes_match\", 0.0)\n",
    "\n",
    "    # Sort by final_score\n",
    "    df = df.sort_values(\"final_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87d83852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>similarity</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>costa rica  mirazu dcafetal espresso roast sin...</td>\n",
       "      <td>150000</td>\n",
       "      <td>costa rica tarrazu mirazu dcafetal black honey...</td>\n",
       "      <td>0.097683</td>\n",
       "      <td>0.097683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>indonesia  gulang 2817 natural anaerobic  150g</td>\n",
       "      <td>150000</td>\n",
       "      <td>indonesia flores manggarai lot gulang 2817 nat...</td>\n",
       "      <td>0.086921</td>\n",
       "      <td>0.086921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>114000</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>0.068407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fugol coffee roasters</td>\n",
       "      <td>kopi arabika watermelon smash 100 gram natural...</td>\n",
       "      <td>81000</td>\n",
       "      <td>halal id32110016691860324 pirt308327301034727 ...</td>\n",
       "      <td>0.064859</td>\n",
       "      <td>0.064859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swargi roasters</td>\n",
       "      <td>mid grade espresso malt crema 100 arabica  200 gr</td>\n",
       "      <td>65000</td>\n",
       "      <td>malt crema beans yang diroasting khusus untuk ...</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.064742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>ethiopia yirgacheffe  arabica specialty coffee...</td>\n",
       "      <td>301500</td>\n",
       "      <td>ethiopia yirgacheffe  specialty coffee  collin...</td>\n",
       "      <td>0.063927</td>\n",
       "      <td>0.063927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a roastworks</td>\n",
       "      <td>black  gold espresso blend  a roastworks  biji...</td>\n",
       "      <td>245000</td>\n",
       "      <td>black  gold espresso blend brazil alto caparao...</td>\n",
       "      <td>0.062753</td>\n",
       "      <td>0.062753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>yunnan mengzhu honey asd  filter specialty cof...</td>\n",
       "      <td>130000</td>\n",
       "      <td>yunnan mengzhu honey asd  filter specialty cof...</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>0.056469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arutala coffee</td>\n",
       "      <td>arutala kopi vietnam central highland robusta ...</td>\n",
       "      <td>260900</td>\n",
       "      <td>kenapa arutala coffee dengan memiliki roastery...</td>\n",
       "      <td>0.053666</td>\n",
       "      <td>0.053666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arutala coffee</td>\n",
       "      <td>arutala kopi colombia decaf arabika 200 gram  ...</td>\n",
       "      <td>139900</td>\n",
       "      <td>kenapa arutala coffee dengan memiliki roastery...</td>\n",
       "      <td>0.053493</td>\n",
       "      <td>0.053493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source                                               name  \\\n",
       "0  tatido coffee roasters  costa rica  mirazu dcafetal espresso roast sin...   \n",
       "1  tatido coffee roasters     indonesia  gulang 2817 natural anaerobic  150g   \n",
       "2        collins roasters  bali karana madu honey anaerobic  collins roas...   \n",
       "3   fugol coffee roasters  kopi arabika watermelon smash 100 gram natural...   \n",
       "4         swargi roasters  mid grade espresso malt crema 100 arabica  200 gr   \n",
       "5        collins roasters  ethiopia yirgacheffe  arabica specialty coffee...   \n",
       "6            a roastworks  black  gold espresso blend  a roastworks  biji...   \n",
       "7        collins roasters  yunnan mengzhu honey asd  filter specialty cof...   \n",
       "8          arutala coffee  arutala kopi vietnam central highland robusta ...   \n",
       "9          arutala coffee  arutala kopi colombia decaf arabika 200 gram  ...   \n",
       "\n",
       "    price                                        description  similarity  \\\n",
       "0  150000  costa rica tarrazu mirazu dcafetal black honey...    0.097683   \n",
       "1  150000  indonesia flores manggarai lot gulang 2817 nat...    0.086921   \n",
       "2  114000  bali karana madu honey anaerobic  collins roas...    0.068407   \n",
       "3   81000  halal id32110016691860324 pirt308327301034727 ...    0.064859   \n",
       "4   65000  malt crema beans yang diroasting khusus untuk ...    0.064742   \n",
       "5  301500  ethiopia yirgacheffe  specialty coffee  collin...    0.063927   \n",
       "6  245000  black  gold espresso blend brazil alto caparao...    0.062753   \n",
       "7  130000  yunnan mengzhu honey asd  filter specialty cof...    0.056469   \n",
       "8  260900  kenapa arutala coffee dengan memiliki roastery...    0.053666   \n",
       "9  139900  kenapa arutala coffee dengan memiliki roastery...    0.053493   \n",
       "\n",
       "   final_score  \n",
       "0     0.097683  \n",
       "1     0.086921  \n",
       "2     0.068407  \n",
       "3     0.064859  \n",
       "4     0.064742  \n",
       "5     0.063927  \n",
       "6     0.062753  \n",
       "7     0.056469  \n",
       "8     0.053666  \n",
       "9     0.053493  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUick check\n",
    "final_results = rerank_candidates(results, user_profile, ranking_config)\n",
    "\n",
    "final_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f85c1",
   "metadata": {},
   "source": [
    "Based on the final_results, the final recommendation order aligns well with both business expectations and the user’s contextual preferences. The top-ranked products are dominated by washed single-origin coffees with clean and fruity profiles—items that were already strong candidates at the TF-IDF stage and were not subject to any penalties. This indicates that the ranking and penalty layer does not distort the initial retrieval results, but instead acts as a refinement and validation step.\n",
    "\n",
    "Notably, the final_score for most top candidates remains identical to their original similarity score. From a business perspective, this is a positive signal: it shows that the system does not enforce rules aggressively by default, and only intervenes when necessary. In other words, the ranking layer is designed to be non-intrusive, applying corrections only when contextual mismatches are detected.\n",
    "\n",
    "From a recommendation quality standpoint, the top results come from multiple roasteries with consistent product characteristics (washed, filter-friendly, non-capsule, non-tools). This demonstrates that the system avoids brand bias and prioritizes contextual alignment with user preferences. Additionally, the presence of a reasonable price range among top-ranked items allows users to make trade-offs based on budget without sacrificing relevance.\n",
    "\n",
    "Overall, these results confirm that the recommendation pipeline functions as intended: TF-IDF serves as a robust retrieval mechanism for identifying relevant candidates, while the ranking and penalty layer operates as a business guardrail—ensuring the final recommendations are practical, context-aware, and aligned with a responsible user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4f074b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before rerank (top 5 by similarity):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>costa rica  mirazu dcafetal espresso roast sin...</td>\n",
       "      <td>150000</td>\n",
       "      <td>costa rica tarrazu mirazu dcafetal black honey...</td>\n",
       "      <td>0.097683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>indonesia  gulang 2817 natural anaerobic  150g</td>\n",
       "      <td>150000</td>\n",
       "      <td>indonesia flores manggarai lot gulang 2817 nat...</td>\n",
       "      <td>0.086921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>114000</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>0.068407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>fugol coffee roasters</td>\n",
       "      <td>kopi arabika watermelon smash 100 gram natural...</td>\n",
       "      <td>81000</td>\n",
       "      <td>halal id32110016691860324 pirt308327301034727 ...</td>\n",
       "      <td>0.064859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>swargi roasters</td>\n",
       "      <td>mid grade espresso malt crema 100 arabica  200 gr</td>\n",
       "      <td>65000</td>\n",
       "      <td>malt crema beans yang diroasting khusus untuk ...</td>\n",
       "      <td>0.064742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source  \\\n",
       "187  tatido coffee roasters   \n",
       "186  tatido coffee roasters   \n",
       "299        collins roasters   \n",
       "172   fugol coffee roasters   \n",
       "275         swargi roasters   \n",
       "\n",
       "                                                  name   price  \\\n",
       "187  costa rica  mirazu dcafetal espresso roast sin...  150000   \n",
       "186     indonesia  gulang 2817 natural anaerobic  150g  150000   \n",
       "299  bali karana madu honey anaerobic  collins roas...  114000   \n",
       "172  kopi arabika watermelon smash 100 gram natural...   81000   \n",
       "275  mid grade espresso malt crema 100 arabica  200 gr   65000   \n",
       "\n",
       "                                           description  similarity  \n",
       "187  costa rica tarrazu mirazu dcafetal black honey...    0.097683  \n",
       "186  indonesia flores manggarai lot gulang 2817 nat...    0.086921  \n",
       "299  bali karana madu honey anaerobic  collins roas...    0.068407  \n",
       "172  halal id32110016691860324 pirt308327301034727 ...    0.064859  \n",
       "275  malt crema beans yang diroasting khusus untuk ...    0.064742  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After rerank (top 5 by final_score):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>similarity</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>costa rica  mirazu dcafetal espresso roast sin...</td>\n",
       "      <td>150000</td>\n",
       "      <td>costa rica tarrazu mirazu dcafetal black honey...</td>\n",
       "      <td>0.097683</td>\n",
       "      <td>0.097683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tatido coffee roasters</td>\n",
       "      <td>indonesia  gulang 2817 natural anaerobic  150g</td>\n",
       "      <td>150000</td>\n",
       "      <td>indonesia flores manggarai lot gulang 2817 nat...</td>\n",
       "      <td>0.086921</td>\n",
       "      <td>0.086921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collins roasters</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>114000</td>\n",
       "      <td>bali karana madu honey anaerobic  collins roas...</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>0.068407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fugol coffee roasters</td>\n",
       "      <td>kopi arabika watermelon smash 100 gram natural...</td>\n",
       "      <td>81000</td>\n",
       "      <td>halal id32110016691860324 pirt308327301034727 ...</td>\n",
       "      <td>0.064859</td>\n",
       "      <td>0.064859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swargi roasters</td>\n",
       "      <td>mid grade espresso malt crema 100 arabica  200 gr</td>\n",
       "      <td>65000</td>\n",
       "      <td>malt crema beans yang diroasting khusus untuk ...</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.064742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   source                                               name  \\\n",
       "0  tatido coffee roasters  costa rica  mirazu dcafetal espresso roast sin...   \n",
       "1  tatido coffee roasters     indonesia  gulang 2817 natural anaerobic  150g   \n",
       "2        collins roasters  bali karana madu honey anaerobic  collins roas...   \n",
       "3   fugol coffee roasters  kopi arabika watermelon smash 100 gram natural...   \n",
       "4         swargi roasters  mid grade espresso malt crema 100 arabica  200 gr   \n",
       "\n",
       "    price                                        description  similarity  \\\n",
       "0  150000  costa rica tarrazu mirazu dcafetal black honey...    0.097683   \n",
       "1  150000  indonesia flores manggarai lot gulang 2817 nat...    0.086921   \n",
       "2  114000  bali karana madu honey anaerobic  collins roas...    0.068407   \n",
       "3   81000  halal id32110016691860324 pirt308327301034727 ...    0.064859   \n",
       "4   65000  malt crema beans yang diroasting khusus untuk ...    0.064742   \n",
       "\n",
       "   final_score  \n",
       "0     0.097683  \n",
       "1     0.086921  \n",
       "2     0.068407  \n",
       "3     0.064859  \n",
       "4     0.064742  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(\"Before rerank (top 5 by similarity):\")\n",
    "display(results.head(5))\n",
    "\n",
    "print(\"After rerank (top 5 by final_score):\")\n",
    "display(final_results.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751bda16",
   "metadata": {},
   "source": [
    "---\n",
    "**Conclusion**\n",
    "\n",
    "---\n",
    "\n",
    "Overall, the recommendation system developed in this project produces final results that are consistent, relevant, and defensible from a business perspective. The TF-IDF and cosine similarity approach serves effectively as a retrieval engine, identifying candidate products based on textual alignment between user preferences and product descriptions. At this stage, the system successfully narrows down the catalog to candidates that are already meaningful in terms of descriptive relevance.\n",
    "\n",
    "The key strength of this solution lies in the ranking and penalty layer. This layer ensures that recommendations are not only textually similar, but also context-aware and practically suitable for the user. By combining hard filters, penalties, and boosts, the system applies corrections selectively—adjusting rankings only when necessary, while remaining non-intrusive when the initial candidates are already appropriate. The observed stability of the final ranking in certain cases confirms that the system avoids unnecessary intervention and is not over-engineered.\n",
    "\n",
    "From a business standpoint, this pipeline strikes a balanced approach between flexibility and control. It does not rely solely on rigid rules, nor does it depend entirely on similarity scores. This balance results in recommendations that are more trustworthy, explainable, and easier to evaluate. With its modular design and transparent logic, the system provides a solid foundation for future enhancements, including rule refinement, data expansion, and eventual production deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a9cd1",
   "metadata": {},
   "source": [
    "# v. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1707e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('artifacts')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new directory folder\n",
    "from pathlib import Path\n",
    "\n",
    "artifact_dir = Path(\"artifacts\")\n",
    "artifact_dir.mkdir(parents=True, exist_ok=True)\n",
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74d93beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts\\\\tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save vectorizer\n",
    "import joblib\n",
    "\n",
    "joblib.dump(vectorizer, artifact_dir / \"tfidf_vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "033a1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature engineered dataset to directory\n",
    "df_fe.to_csv(artifact_dir / \"products_fe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7f2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 24)\n",
      "Index(['source', 'name', 'price', 'description', 'origin', 'process',\n",
      "       'roast_level', 'notes', 'name_clean', 'desc_clean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check saved dataset\n",
    "df_loaded = pd.read_csv(artifact_dir / \"products_fe.csv\")\n",
    "print(df_loaded.shape)\n",
    "print(df_loaded.columns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55366973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ranking config\n",
    "import json\n",
    "\n",
    "with open(artifact_dir / \"ranking_config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ranking_config, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0ee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hard_filter', 'penalty', 'boost'])\n"
     ]
    }
   ],
   "source": [
    "# Check saved ranking config\n",
    "with open(artifact_dir / \"ranking_config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg_loaded = json.load(f)\n",
    "\n",
    "print(cfg_loaded.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05b47041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: artifacts\\products_tfidf_matrix.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save X_tfidf\n",
    "joblib.dump(X_tfidf, artifact_dir / \"products_tfidf_matrix.joblib\")\n",
    "print(\"Saved:\", artifact_dir / \"products_tfidf_matrix.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bc984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (614, 8910)\n"
     ]
    }
   ],
   "source": [
    "# Check saved X_tfidf\n",
    "X_loaded = joblib.load(artifact_dir / \"products_tfidf_matrix.joblib\")\n",
    "print(\"Matrix shape:\", X_loaded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bb8ee01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts\\\\tfidf_features.joblib']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save feature names\n",
    "joblib.dump(vectorizer.get_feature_names_out(), artifact_dir / \"tfidf_features.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_version': '3.9.25',\n",
       " 'sklearn_version': '1.6.1',\n",
       " 'numpy_version': '1.26.4',\n",
       " 'n_products': 614,\n",
       " 'n_features': 8910}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save metadata\n",
    "import platform\n",
    "import sklearn\n",
    "\n",
    "meta = {\n",
    "    \"python_version\": platform.python_version(),\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"numpy_version\": np.__version__,\n",
    "    \"n_products\": int(df_fe.shape[0]),\n",
    "    \"n_features\": int(X_tfidf.shape[1]) if \"X_tfidf\" in globals() else None,\n",
    "}\n",
    "\n",
    "with open(artifact_dir / \"artifact_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "# Quick check\n",
    "meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacktiv_env (Python 3.9)",
   "language": "python",
   "name": "hacktiv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
